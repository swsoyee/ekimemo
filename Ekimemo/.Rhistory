mean(x0, is,na(x0))
mean(x0, is.na(x0))
mean(is.na(x0))
names(pm1) <- make.names(cnames[[1]][wcol])
dim(pm1)
x1 <- pm1$Sample.Value
mean(is.na(x1))
summary(x0)
summary(x1)
boxplot(x0,x1)
boxplot(log10(x0),log10(x1)
)
negative <- x1<0
sum(negative, na.rm = TRUE)
mean(negative, na.rm = TRUE)
dates <- pm1$Date
str(date)
str(dates)
str(dates)
dates <- as.Date(as.character(dates), "%Y%m%d")
head(dates)
hist(dates[negative], "month")
str(site0)
intersect(site0,site1)
both <- intersect(site0,site1)
both
both
head(pm0)
cnt0 <- subset(pm0)
cnt0 <- subset(pm0, State.Code == 36 & county.site %in% both)
cnt1 <- subset(pm1, State.Code == 36 & county.site %in% both)
sapply(split(cnt0, cnt0$county.site), nrow)
sapply(split(cnt1, cnt1$county.site), nrow)
pm0sub <- subset(cnt0, County.Code ==63 & Site.ID == 2008)
pm1sub <- subset(cnt1, County.Code ==63 & Site.ID == 2008)
x0sub <- pm0sub$Sample.Value
x1sub <- pm1sub$Sample.Value
dates0 <- as.Date()
dates0 <- as.Date(as.character(pm0sub$Date), "%Y%m%d")
dates1 <- as.Date(as.character(pm1sub$Date), "%Y%m%d")
dates1 <- as.Date(as.character(pm1sub$Date), "%Y%m%d")
par(mfrow = c(1, 2), mar = c(4, 4, 2, 1))
plot(dates0,x0sub, pch = 20)
abline(pm25, lwd = 2)
abline(median(x0sub), lwd = 2, na.rm = TRUE)
dates1 <- as.Date(as.character(pm1sub$Date), "%Y%m%d")
abline(h = median(x0sub, na.rm = TRUE),lwd=2)
plot(dates1,x1sub, pch = 20)
abline(h = median(x1sub, na.rm = TRUE),lwd=2)
abline(h = median(x1sub, na.rm = TRUE),lwd=2)
rng <- range(x0sub,x1sub,na.rm=TRUE)
rng
mn0 <- with(pm0, tapply(Sample.Value, State.Code, mean, nr.rm = TRUE))
mn0 <- with(pm0, tapply(Sample.Value, State.Code, mean, na.rm = TRUE))
str(mn0)
mn1 <- with(pm1, tapply(Sample.Value, State.Code, mean, na.rm = TRUE))
str(mn1)
summary(mn0)
summary(mn1)
summary(mn1)
d0 <- data.frame(state = names(mn0), mean = mn0)
d1 <- data.frame(state = names(mn1), mean = mn1)
mrg <- merge(d0,d1,by = "state")
dim(mrg)
head(mrg)
head(mrg)
rep(1, 52)
with(mrg, plot(rep(1, 52), mrg[, 2], xlim = c(.5, 2.5)))
with(mrg, plot(rep(1, 52), mrg[, 3], xlim = c(.5, 2.5)))
with(mrg, points(rep(2, 52), mrg[, 3]))
with(mrg, points(rep(2, 52), mrg[, 3]))
segments(rep(1, 52), mrg[, 2], rep(2, 52), mrg[, 3])
mrg[mrg$mean.x < mrg$mean.y, ]
library("KernSmooth")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
tmp <- tempdir()
download.file(fileUrl, tmp, method = "curl")
library("data.table")
dt <- data.table(tmp)
View(dt)
?data.table
list.files(tmp)
list.files(tmp)[2]
tmp
dt <- read.csv(fileUrl)
head(dt)
View(dt)
dt[,"VAL">1000000]
dt[dt$VAL>1000000]
class(dt)
dt1 <- data.table(fileUrl)
dt1[dt1$VAL>1000000]
dt1 <- data.table(dt)
dt1[dt1$VAL>1000000]
dt1[dt1$VAL>1000000,]
View(dt1)
tables()
dt[VAL>1000000]
dt1[VAL>1000000]
dt1[VAL>100000]
dt1[VAL>10000]
dt1[VAL>10]
dt1[VAL>100]
dt1[VAL>24]
unique(dt1[VAL])
dt1[VAL]
View(dt1)
dt1[VAL>10]
dt1[VAL>11]
dt1[VAL>20]
dt1[VAL>23]
dt1[VAL>24]
nrow(dt1[VAL>23])
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
install.packages("XLConnect")
library("XLConnect")
dt <- loadWorkbook(fileUrl, create = TRUE)
install.packages("xlsx")
library("xlsx")
dt <- read.xlsx(fileUrl, sheetIndex = 1,rowIndex = 18:23,colIndex = 7:15)
dt <- read.xlsx(fileUrl, sheetIndex = 1,rowIndex = 18:23,colIndex = 7:15)
dt2 <- read.xlsx(fileUrl, sheetIndex = 1,rowIndex = 18:23,colIndex = 7:15)
dt2 <- read.xlsx("D://getdata%2Fdata%2FDATA.gov_NGAP.xlsx", sheetIndex = 1,rowIndex = 18:23,colIndex = 7:15)
dat <- read.xlsx("D://getdata%2Fdata%2FDATA.gov_NGAP.xlsx", sheetIndex = 1,rowIndex = 18:23,colIndex = 7:15)
sum(dat$Zip*dat$Ext,na.rm=T)
library(XML)
dat <- xmlTreeParse(fileUrl)
dat <- xmlTreeParse(fileUrl, useInternet = TRUE)
dat <- xmlTreeParse(fileUrl, useInternalNodes =  = TRUE)
dat <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
library(RCurl)
library(httr)
set_config( config( ssl_verifypeer = 0L ) )
dat <- xmlTreeParse(fileUrl)
download.file(fileUrl)
download.file(fileUrl, tmp,method = "curl")
tmp <- tempfile()
download.file(fileUrl, tmp,method = "curl")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
dat <- xmlTreeParse(fileUrl)
dat <- htmlTreeParse(fileUrl)
dat
xmlTreeParse
dat <- xmlTreeParse(fileUrl)
dat <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
dat <- htmlTreeParse(fileUrl)
xpathSApply(dat, "//li[@class='restaurants']", xmlValue)
xmlRoot(dat)
dt <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(DT[,mean(pwgtp15),by=SEX])
DT <- dt
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
fname <- "restaurants.xml"
download_if_not_exists(fname, "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
doc <- xmlParse(fname)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
dat <- xmlParse(fileUrl)
dt <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
funs <- list(
fun1 = function() { sapply(split(DT$pwgtp15,DT$SEX),mean) },
fun2 = function() { tapply(DT$pwgtp15,DT$SEX,mean) },
fun3 = function() { mean(DT$pwgtp15,by=DT$SEX) },
fun4 = function() { DT[,mean(pwgtp15),by=SEX] },
fun5 = function() { rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2] },
fun6 = function() { mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15) }
)
debug <- TRUE
fastest <- NULL
min <- .Machine$integer.max
lapply(funs, function(FUN) {
if (debug) print(FUN)
st <- system.time(x <- try(FUN(), silent = TRUE))
if (inherits(x, "try-error")) {
if(debug) print("run-time error, skipping..")
} else {
et <- st[3]
if (et < min) {
min <<- et
fastest <<- FUN
}
if (debug) {
print(paste("elapsed time:", sprintf("%.10f", et)))
print(x)
}
}
})
## The function 'mean(DT$pwgtp15,by=DT$SEX)' should be the fastest one.
print("The fastest calculation is:")
print(fastest)
msg("with running time of", sprintf("%.10f", min), "seconds")
debug <- FALSE
lapply(funs, function(FUN) {
if (debug) print(FUN)
st <- system.time(x <- try(FUN(), silent = TRUE))
if (inherits(x, "try-error")) {
if(debug) print("run-time error, skipping..")
} else {
et <- st[3]
if (et < min) {
min <<- et
fastest <<- FUN
}
if (debug) {
print(paste("elapsed time:", sprintf("%.10f", et)))
print(x)
}
}
})
print("The fastest calculation is:")
print(fastest)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
dt <- read.table(fileUrl)
dt <- read.table(fileUrl)
dt <- read.table(fileUrl, sep = "\t")
head(dt)
View(dt)
install.packages("readr")
library("readr")
x <- read.fwf(file=fileUrl, skip=4, widths=c(12, 7, 4, 9, 4, 9, 4, 9, 4))
sum(x$V4)
View(x)
library("httr")
html <- GET(fileUrl)
library(RCurl)
library(httr)
set_config( config( ssl_verifypeer = 0L ) )
html <- GET(fileUrl)
content <- content(html,as = "text")
library("XML")
prasedHtml <- htmlParse(content, asText = TRUE)
names(prasedHtml)
head(content)
prasedHtml <- htmlParse(content, asText = TRUE)
htmlCode <- readLines(html)
con <- url(fileUrl)
htmlCode <- readLines(con)
htmlCode[1]
htmlCode[c(10,20,30,100)]
nchar(htmlCode[c(10,20,30,100)])
fileUrl <- "http://biostat.jhsph.edu/~jleek/contact.html"
con <- url(fileUrl)
htmlCode <- readLines(con)
html <- GET(fileUrl)
content <- content(html,as = "text")
prasedHtml <- htmlParse(content, asText = TRUE)
names(prasedHtml)
con <- url(fileUrl)
htmlCode <- readLines(con)
nchar(htmlCode[c(10,20,30,100)])
install.packages("sqldf")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
acs <- read.csv(fileUrl)
head(acs)
sqldf("select pwgtp1 from acs where AGEP < 50")
library("sqldf")
sqldf("select pwgtp1 from acs where AGEP < 50")
way1 <- unique(acs$AGEP)
way2 <- sqldf("select distinct AGEP from acs")
way1 == way2
install.packages("jsonlite")
fileUrl <- "https://api.github.com/users/jtleek/repos"
jsonData <- fromJSON(fileUrl)
library(jsonlite)
jsonData <- fromJSON(fileUrl)
names(jsonData)
jsonData$created_at
names(jsonData$created_at)
jsonData$name == "datasharing"
jsonData[jsonData$name == "datasharing",]
jsonData[jsonData$name == "datasharing",]$created_at
library(swirl)
swirl()
install_course("Practical R Exercises in swirl")
library(RCurl)
library(httr)
set_config( config( ssl_verifypeer = 0L ) )
install_course("Practical R Exercises in swirl")
install_course("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
package_version(dplyr)
package_version("dplyr")
packageVersion("dplyr")
cran <- tbl_df(mydf)
rrm("mydf")
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
View(cran)
View(cran)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(4:ncol(cran)))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version == "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
ilter(cran,
country == "US" | country == "IN")
filter(cran,
country == "US" | country == "IN")
filter(cran, size > 100500 & r_os == "linux-gun")
filter(cran, size > 100500 & r_os == "linux-gnu")
filter(cran, size > 100500 , r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.no(r_version) )
filter(cran, !is.na(r_version) )
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country,desc(r_version), ip_id)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb/2^10)
mutate(cran3, correct_size = size+1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(cran)
cran <- tbl_df(mydf)
rm(mddf)
rm(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran,package)
by_package
by_package
summarise(by_package,mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count>679)
top_counts
view(top_counts)
View(top_counts)
top_counts_sorted <- arrange(top_counts, count)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(count))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
more
now()
a
x <-1
submit()
submit()
library(tidyr)
students
?gather
View(students)
gather(students, sex, count, -grade)
students2
gather(students2, sex_class, count, -grade)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(data = res, col = sex_class, into = c("sex","class"))
submit()
students3
submit()
?spread
submit()
submit()
library(readr)
parse_number("class5")
submit()
submit()
?mutate
submit()
students4
submit()
submit()
submit()
submit()
passed
failed
passed <- mutate(passed, status = "passed")
failed <- mutate(failed, status = "failed")
bind_rows(passed,failed)
sat
submit()
submit()
submit()
install.packages("rmarkdown")
install.packages("rticles")
install.packages("formatR")
install.packages("rticles")
library("rticles", lib.loc="D:/R-3.3.3/library")
library(rticles)
install.packages("knitr")
library(knitr)
library("rmarkdown", lib.loc="D:/R-3.3.3/library")
library("rticles", lib.loc="D:/R-3.3.3/library")
install.packages("rmarkdown")
library("rmarkdown", lib.loc="D:/R-3.3.3/library")
library(rmarkdown)
remove.packages("rmarkdown")
install.packages("rmarkdown")
library("rmarkdown", lib.loc="D:/R-3.3.3/library")
install.packages("backports")
library("rmarkdown", lib.loc="D:/R-3.3.3/library")
options(digits = 4)
fit = lm(dist ~ speed, data = cars)
coef(summary(fit))
b = coef(fit)
par(mar = c(4, 4, .1, .1), las = 1)
plot(cars, pch = 19)
abline(fit, col = 'red')
options(digits = 4)
fit = lm(dist ~ speed, data = cars)
coef(summary(fit))
b = coef(fit)
par(mar = c(4, 4, .1, .1), las = 1)
plot(cars, pch = 19)
abline(fit, col = 'red')
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
shiny::runApp('D:/ekimemo/Ekimemo')
shiny::runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
setwd("D:/ekimemo/Ekimemo")
View(prefCSV)
shiny::runApp()
runApp()
prefCSV[prefCSV$pref_cd == 13, ]$pref_name
runApp()
runApp()
runApp()
library(shiny)
?checkboxGroupInput
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
dt1
dt1 <- data.table(dt1)
dt1
dt1 %>% group_by(line_name) %>% summarise(Total = n())
dt1 %>% group_by(line_name) %>% summarise(Total = n(), Check = sum(select))
head(dt1 %>% group_by(line_name) %>% summarise(Total = n(), Check = sum(select)), n =60)
dt1 %>% group_by(line_name) %>% summarise(Precentage = paste(sum(select), "/", n() ))
runApp()
paste0("select", 1:47)
runApp()
runApp()
runApp()
