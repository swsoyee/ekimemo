segments(rep(1, 52), mrg[, 2], rep(2, 52), mrg[, 3])
mrg[mrg$mean.x < mrg$mean.y, ]
library("KernSmooth")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
tmp <- tempdir()
download.file(fileUrl, tmp, method = "curl")
library("data.table")
dt <- data.table(tmp)
View(dt)
?data.table
list.files(tmp)
list.files(tmp)[2]
tmp
dt <- read.csv(fileUrl)
head(dt)
View(dt)
dt[,"VAL">1000000]
dt[dt$VAL>1000000]
class(dt)
dt1 <- data.table(fileUrl)
dt1[dt1$VAL>1000000]
dt1 <- data.table(dt)
dt1[dt1$VAL>1000000]
dt1[dt1$VAL>1000000,]
View(dt1)
tables()
dt[VAL>1000000]
dt1[VAL>1000000]
dt1[VAL>100000]
dt1[VAL>10000]
dt1[VAL>10]
dt1[VAL>100]
dt1[VAL>24]
unique(dt1[VAL])
dt1[VAL]
View(dt1)
dt1[VAL>10]
dt1[VAL>11]
dt1[VAL>20]
dt1[VAL>23]
dt1[VAL>24]
nrow(dt1[VAL>23])
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
install.packages("XLConnect")
library("XLConnect")
dt <- loadWorkbook(fileUrl, create = TRUE)
install.packages("xlsx")
library("xlsx")
dt <- read.xlsx(fileUrl, sheetIndex = 1,rowIndex = 18:23,colIndex = 7:15)
dt <- read.xlsx(fileUrl, sheetIndex = 1,rowIndex = 18:23,colIndex = 7:15)
dt2 <- read.xlsx(fileUrl, sheetIndex = 1,rowIndex = 18:23,colIndex = 7:15)
dt2 <- read.xlsx("D://getdata%2Fdata%2FDATA.gov_NGAP.xlsx", sheetIndex = 1,rowIndex = 18:23,colIndex = 7:15)
dat <- read.xlsx("D://getdata%2Fdata%2FDATA.gov_NGAP.xlsx", sheetIndex = 1,rowIndex = 18:23,colIndex = 7:15)
sum(dat$Zip*dat$Ext,na.rm=T)
library(XML)
dat <- xmlTreeParse(fileUrl)
dat <- xmlTreeParse(fileUrl, useInternet = TRUE)
dat <- xmlTreeParse(fileUrl, useInternalNodes =  = TRUE)
dat <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
library(RCurl)
library(httr)
set_config( config( ssl_verifypeer = 0L ) )
dat <- xmlTreeParse(fileUrl)
download.file(fileUrl)
download.file(fileUrl, tmp,method = "curl")
tmp <- tempfile()
download.file(fileUrl, tmp,method = "curl")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
dat <- xmlTreeParse(fileUrl)
dat <- htmlTreeParse(fileUrl)
dat
xmlTreeParse
dat <- xmlTreeParse(fileUrl)
dat <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
dat <- htmlTreeParse(fileUrl)
xpathSApply(dat, "//li[@class='restaurants']", xmlValue)
xmlRoot(dat)
dt <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(DT[,mean(pwgtp15),by=SEX])
DT <- dt
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
fname <- "restaurants.xml"
download_if_not_exists(fname, "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
doc <- xmlParse(fname)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
dat <- xmlParse(fileUrl)
dt <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
funs <- list(
fun1 = function() { sapply(split(DT$pwgtp15,DT$SEX),mean) },
fun2 = function() { tapply(DT$pwgtp15,DT$SEX,mean) },
fun3 = function() { mean(DT$pwgtp15,by=DT$SEX) },
fun4 = function() { DT[,mean(pwgtp15),by=SEX] },
fun5 = function() { rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2] },
fun6 = function() { mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15) }
)
debug <- TRUE
fastest <- NULL
min <- .Machine$integer.max
lapply(funs, function(FUN) {
if (debug) print(FUN)
st <- system.time(x <- try(FUN(), silent = TRUE))
if (inherits(x, "try-error")) {
if(debug) print("run-time error, skipping..")
} else {
et <- st[3]
if (et < min) {
min <<- et
fastest <<- FUN
}
if (debug) {
print(paste("elapsed time:", sprintf("%.10f", et)))
print(x)
}
}
})
## The function 'mean(DT$pwgtp15,by=DT$SEX)' should be the fastest one.
print("The fastest calculation is:")
print(fastest)
msg("with running time of", sprintf("%.10f", min), "seconds")
debug <- FALSE
lapply(funs, function(FUN) {
if (debug) print(FUN)
st <- system.time(x <- try(FUN(), silent = TRUE))
if (inherits(x, "try-error")) {
if(debug) print("run-time error, skipping..")
} else {
et <- st[3]
if (et < min) {
min <<- et
fastest <<- FUN
}
if (debug) {
print(paste("elapsed time:", sprintf("%.10f", et)))
print(x)
}
}
})
print("The fastest calculation is:")
print(fastest)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
dt <- read.table(fileUrl)
dt <- read.table(fileUrl)
dt <- read.table(fileUrl, sep = "\t")
head(dt)
View(dt)
install.packages("readr")
library("readr")
x <- read.fwf(file=fileUrl, skip=4, widths=c(12, 7, 4, 9, 4, 9, 4, 9, 4))
sum(x$V4)
View(x)
library("httr")
html <- GET(fileUrl)
library(RCurl)
library(httr)
set_config( config( ssl_verifypeer = 0L ) )
html <- GET(fileUrl)
content <- content(html,as = "text")
library("XML")
prasedHtml <- htmlParse(content, asText = TRUE)
names(prasedHtml)
head(content)
prasedHtml <- htmlParse(content, asText = TRUE)
htmlCode <- readLines(html)
con <- url(fileUrl)
htmlCode <- readLines(con)
htmlCode[1]
htmlCode[c(10,20,30,100)]
nchar(htmlCode[c(10,20,30,100)])
fileUrl <- "http://biostat.jhsph.edu/~jleek/contact.html"
con <- url(fileUrl)
htmlCode <- readLines(con)
html <- GET(fileUrl)
content <- content(html,as = "text")
prasedHtml <- htmlParse(content, asText = TRUE)
names(prasedHtml)
con <- url(fileUrl)
htmlCode <- readLines(con)
nchar(htmlCode[c(10,20,30,100)])
install.packages("sqldf")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
acs <- read.csv(fileUrl)
head(acs)
sqldf("select pwgtp1 from acs where AGEP < 50")
library("sqldf")
sqldf("select pwgtp1 from acs where AGEP < 50")
way1 <- unique(acs$AGEP)
way2 <- sqldf("select distinct AGEP from acs")
way1 == way2
install.packages("jsonlite")
fileUrl <- "https://api.github.com/users/jtleek/repos"
jsonData <- fromJSON(fileUrl)
library(jsonlite)
jsonData <- fromJSON(fileUrl)
names(jsonData)
jsonData$created_at
names(jsonData$created_at)
jsonData$name == "datasharing"
jsonData[jsonData$name == "datasharing",]
jsonData[jsonData$name == "datasharing",]$created_at
library(swirl)
swirl()
install_course("Practical R Exercises in swirl")
library(RCurl)
library(httr)
set_config( config( ssl_verifypeer = 0L ) )
install_course("Practical R Exercises in swirl")
install_course("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
package_version(dplyr)
package_version("dplyr")
packageVersion("dplyr")
cran <- tbl_df(mydf)
rrm("mydf")
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
View(cran)
View(cran)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(4:ncol(cran)))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version == "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
ilter(cran,
country == "US" | country == "IN")
filter(cran,
country == "US" | country == "IN")
filter(cran, size > 100500 & r_os == "linux-gun")
filter(cran, size > 100500 & r_os == "linux-gnu")
filter(cran, size > 100500 , r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.no(r_version) )
filter(cran, !is.na(r_version) )
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country,desc(r_version), ip_id)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb/2^10)
mutate(cran3, correct_size = size+1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(cran)
cran <- tbl_df(mydf)
rm(mddf)
rm(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran,package)
by_package
by_package
summarise(by_package,mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count>679)
top_counts
view(top_counts)
View(top_counts)
top_counts_sorted <- arrange(top_counts, count)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(count))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
more
now()
a
x <-1
submit()
submit()
library(tidyr)
students
?gather
View(students)
gather(students, sex, count, -grade)
students2
gather(students2, sex_class, count, -grade)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(data = res, col = sex_class, into = c("sex","class"))
submit()
students3
submit()
?spread
submit()
submit()
library(readr)
parse_number("class5")
submit()
submit()
?mutate
submit()
students4
submit()
submit()
submit()
submit()
passed
failed
passed <- mutate(passed, status = "passed")
failed <- mutate(failed, status = "failed")
bind_rows(passed,failed)
sat
submit()
submit()
submit()
install.packages("rmarkdown")
install.packages("rticles")
install.packages("formatR")
install.packages("rticles")
library("rticles", lib.loc="D:/R-3.3.3/library")
library(rticles)
install.packages("knitr")
library(knitr)
library("rmarkdown", lib.loc="D:/R-3.3.3/library")
library("rticles", lib.loc="D:/R-3.3.3/library")
install.packages("rmarkdown")
library("rmarkdown", lib.loc="D:/R-3.3.3/library")
library(rmarkdown)
remove.packages("rmarkdown")
install.packages("rmarkdown")
library("rmarkdown", lib.loc="D:/R-3.3.3/library")
install.packages("backports")
library("rmarkdown", lib.loc="D:/R-3.3.3/library")
options(digits = 4)
fit = lm(dist ~ speed, data = cars)
coef(summary(fit))
b = coef(fit)
par(mar = c(4, 4, .1, .1), las = 1)
plot(cars, pch = 19)
abline(fit, col = 'red')
options(digits = 4)
fit = lm(dist ~ speed, data = cars)
coef(summary(fit))
b = coef(fit)
par(mar = c(4, 4, .1, .1), las = 1)
plot(cars, pch = 19)
abline(fit, col = 'red')
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
shiny::runApp('D:/ekimemo/Ekimemo')
shiny::runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
head(variables$database)
head(variables$database)$staion_cd
head(variables$database$staion_cd)
head(variables$database$station_cd)
variables$database$station_cd %in% stationCode
variables$database[variables$database$station_cd %in% stationCode, ]
variables$database[variables$database$station_cd %in% stationCode, ]$select
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
variables
variables$database
variables
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
filter(variables$database, line_name %in% addLine)
variables$database
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
?datatable
library(shiny)
ui <- fluidPage(
actionButton("go", "Click me"),
helpText("All values in the table below are incremented ",
"each time you press the button"),
tableOutput("tbl")
)
server <- function(input, output, session) {
x <- reactiveVal(data.frame(matrix(c(1,2,3,4), nrow = 2)))
observeEvent(input$go, {
x(x() + 1)
})
output$tbl <- renderTable({
x()
})
}
shinyApp(ui, server)
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
variables$database
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
head(variables$database)
runApp('D:/ekimemo/Ekimemo')
head(variables$database)
head(variables$database)
t1 <- filter(variables$database, line_name %in% unique(tmpDt$line_name))
unique(tmpDt$line_name)
variables$database$line_name %in% unique(tmpDt$line_name)
t1 <- variables$database[variables$database$line_name %in% unique(tmpDt$line_name)), ]
t1 <- variables$database[variables$database$line_name %in% unique(tmpDt$line_name), ]
head(variables$database)
head(t1)
tmpDt[which(tmpDt$select == 1), ]$station_cd
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
runApp('D:/ekimemo/Ekimemo')
dt %>% group_by(pref_cd) %>% summarise("ekisuu" = n())
dt %>% group_by(pref_cd) %>% summarise("ekisuu" = n(), "kansei" = sum(select))
runApp('D:/ekimemo/Ekimemo')
prefCSV <- fread(file = "db\\pref.csv", header = TRUE, encoding = "UTF-8")
setwd(D:\ekimemo\Ekimemo)
setwd("D:\ekimemo\Ekimemo")
setwd("D:\\ekimemo\\Ekimemo")
prefCSV <- fread(file = "db\\pref.csv", header = TRUE, encoding = "UTF-8")
prefCSV <- fread(file = "db\\pref.csv", header = TRUE, encoding = "UTF-8")
prefCSV <- fread(file = "db\\pref.csv", header = TRUE, encoding = "UTF-8")
